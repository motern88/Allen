'''
æ­¤è„šæœ¬ç”¨äºæµ‹è¯•MASåŸºç¡€æç¤ºè¯æ˜¯å¦å¯ä»¥åˆ©ç”¨KVCacheç¼“å­˜æ•ˆæœ
æµ‹è¯•åœºæ™¯ï¼šç›¸åŒMASåŸºç¡€æç¤ºè¯(å‰ç¼€ä¸å˜) + ä¸åŒAgentè§’è‰²
æ‰§è¡Œæµç¨‹: 
1. ç»´æŠ¤å…¨å±€å”¯ä¸€çš„ä¸€ä¸ªLLMClientå’ŒLLMContextå¯¹è±¡
2. è®¾ç½®MASåŸºç¡€æç¤ºè¯ï¼ˆå›ºå®šå‰ç¼€ï¼‰
3. å¾ªç¯æµ‹è¯•ä¸åŒAgentè§’è‰²(3æ¬¡)
   -->å‘é€ä»»åŠ¡è¯·æ±‚-->è®°å½•å“åº”æ—¶é—´-->ç²¾ç¡®æ¸…ç†éå‰ç¼€éƒ¨åˆ†-->éªŒè¯å‰ç¼€å®Œæ•´æ€§
4.åˆ†æç¼“å­˜æ•ˆæœ

è¿è¡Œç»“æœç¤ºä¾‹ï¼š
  ğŸ”„ ç¬¬1æ¬¡æµ‹è¯•: ç°é£ (å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç®¡ç†è€…)
     å¼€å§‹å‰Contexté•¿åº¦: 1
     æ·»åŠ è§’è‰²åContexté•¿åº¦: 2
     å“åº”æ—¶é—´: 12.62s

  ğŸ”„ ç¬¬2æ¬¡æµ‹è¯•: ç°é£ (å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç®¡ç†è€…)
     å¼€å§‹å‰Contexté•¿åº¦: 1
     æ·»åŠ è§’è‰²åContexté•¿åº¦: 2
     å“åº”æ—¶é—´: 11.15s

  ğŸ”„ ç¬¬3æ¬¡æµ‹è¯•: ç°é£ (å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç®¡ç†è€…)
     å¼€å§‹å‰Contexté•¿åº¦: 1
     æ·»åŠ è§’è‰²åContexté•¿åº¦: 2
     å“åº”æ—¶é—´: 12.28s

  ğŸ“ˆ å¹³å‡æ—¶é—´: 12.02s
  ğŸ“Š æ—¶é—´èŒƒå›´: 11.15s - 12.62s

  ğŸ” æ•ˆæœåˆ†æ:
     ç¬¬1æ¬¡å“åº”æ—¶é—´: 12.62s
     åç»­å¹³å‡æ—¶é—´: 11.71s

ç»“è®ºï¼š
ç”±äºç°åœ¨çš„APIéƒ½æ²¡æœ‰çœŸæ­£çš„ä¼šè¯ç®¡ç†ï¼ˆè·¨è¯·æ±‚çš„KV Cacheä¿æŒã€å¯¹è¯çŠ¶æ€è®°å¿†ç­‰ï¼‰ï¼Œè€Œæ˜¯HTTPè¯·æ±‚æ— çŠ¶æ€åœ°è°ƒç”¨ï¼Œå¹¶ä¸æ”¯æŒè·¨è¯·æ±‚çš„KVCacheã€‚
ç›®å‰åªæ”¯æŒå•è¯·æ±‚å†…çš„KV Cacheï¼Œæ‰€ä»¥KV Cacheæ•ˆæœä¸æ˜æ˜¾ã€‚å¾…åç»­LLMæœ¬åœ°éƒ¨ç½²åï¼Œåšé¢å¤–çš„APIä¼šè¯ç®¡ç†ç­‰ä¼˜åŒ–ï¼Œæ‰å¯ä»¥å®ç°çœŸæ­£çš„èŠ‚çº¦tokenå¼€é”€çš„æ•ˆæœã€‚

'''

import time
import json
import statistics
import yaml
import os
from typing import List, Dict, Any
from mas.agent.base.llm_base import LLMClient, LLMContext
from mas.agent.configs.llm_config import LLMConfig
from mas.agent.base.executor_base import Executor

class MASFocusedKVCacheTest(Executor):
    """ä¸“æ³¨æµ‹è¯•MASåŸºç¡€æç¤ºè¯ç¼“å­˜æ•ˆæœçš„éªŒè¯å™¨"""
    
    def __init__(self, config_path: str):
        self.config = LLMConfig.from_yaml(config_path)
        self.llm_client = LLMClient(self.config)
        self.test_results = []
        
        # é¢„åŠ è½½MASåŸºç¡€æç¤ºè¯
        self.mas_base_prompt = self.get_base_prompt()
        print(f"ğŸ“‹ MASåŸºç¡€æç¤ºè¯é•¿åº¦: {len(self.mas_base_prompt)} å­—ç¬¦")

    def execute(self, step_id: str, agent_state: Dict[str, Any], mcp_client=None):
        """å®ç°ExecutoræŠ½è±¡æ–¹æ³•"""
        return {"step_id": step_id, "result": "KVCacheæµ‹è¯•", "status": "finished"}

    def load_agent_config(self, agent_config: str) -> Dict[str, Any]:
        """åŠ è½½Agenté…ç½®æ–‡ä»¶"""
        config_path = f"mas/role_config/{agent_config}"
        with open(config_path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)

    def run_focused_test(self):
        """è¿è¡ŒKVCacheæµ‹è¯•"""
        print("ğŸš€ å¼€å§‹MASåŸºç¡€æç¤ºè¯ç¼“å­˜æ•ˆæœæµ‹è¯•...")
        print("="*60)
        # æµ‹è¯•åœºæ™¯ï¼šç›¸åŒMASåŸºç¡€æç¤ºè¯(å‰ç¼€ä¸å˜) + ä¸åŒAgentè§’è‰²
        self.test_true_prefix_preservation()


    def test_true_prefix_preservation(self):
        """çœŸæ­£çš„å‰ç¼€ä¿æŒæµ‹è¯•"""
        print("\nğŸ“Š æµ‹è¯•ï¼šçœŸæ­£çš„MASå‰ç¼€ä¿æŒä¸å˜")
        
        # ğŸ”‘ å…³é”®ï¼šè®¾ç½®å›ºå®šçš„MASåŸºç¡€æç¤ºè¯ï¼Œä¹‹åç»ä¸åŠ¨
        persistent_context = LLMContext(context_size=30)
        persistent_context.add_message("user", self.mas_base_prompt)

        # ğŸ“ è®°å½•MASåŸºç¡€æç¤ºè¯å¯¹è±¡çš„IDï¼Œåç»­éªŒè¯æ˜¯å¦è¢«åŠ¨è¿‡
        mas_message_id = id(persistent_context.history[0])
        mas_message_content_hash = hash(persistent_context.history[0]["content"])
        
        print(f"  ğŸ”’ MASåŸºç¡€æç¤ºè¯å·²è®¾ç½®ï¼ˆä½ç½®0ï¼‰")
        print(f"  ğŸ“ MASåŸºç¡€æç¤ºè¯é•¿åº¦: {len(self.mas_base_prompt)} å­—ç¬¦")
        print(f"  ğŸ†” MASæ¶ˆæ¯å¯¹è±¡ID: {mas_message_id}")
        print(f"  #ï¸âƒ£  MASå†…å®¹å“ˆå¸Œ: {mas_message_content_hash}")
        
        # åŠ è½½Agenté…ç½®
        agent_configs = ["ç®¡ç†è€…_ç°é£.yaml", "ç®¡ç†è€…_ç°é£.yaml", "ç®¡ç†è€…_ç°é£.yaml"]
        true_kv_times = []
        
        for i, config_file in enumerate(agent_configs):
            try:
                agent_config = self.load_agent_config(config_file)
                agent_name = agent_config.get("name", f"Agent{i+1}")
                agent_role = agent_config.get("role", "æœªçŸ¥è§’è‰²")
                
                # æ„å»ºAgentçŠ¶æ€
                agent_state = {
                    "agent_id": f"agent_{i+1:03d}",
                    "name": agent_name,
                    "role": agent_role,
                    "profile": agent_config.get("profile", "æ— æè¿°")
                }
                
                print(f"\n  ğŸ”„ ç¬¬{i+1}æ¬¡æµ‹è¯•: {agent_name} ({agent_role})")
                print(f"     å¼€å§‹å‰Contexté•¿åº¦: {len(persistent_context.get_history())}")
                
                # ğŸ“ è®°å½•æ·»åŠ å‰çš„é•¿åº¦ï¼Œç”¨äºåç»­ç²¾ç¡®æ¸…ç†
                initial_length = len(persistent_context.get_history())

                agent_role_prompt = self.get_agent_role_prompt(agent_state)
                persistent_context.add_message("user", agent_role_prompt)
                
                print(f"     æ·»åŠ è§’è‰²åContexté•¿åº¦: {len(persistent_context.get_history())}")
                
                # å‘é€ä»»åŠ¡è¯·æ±‚
                task_prompt = "è¯·æ ¹æ®ä½ çš„è§’è‰²åˆ¶å®šä¸€ä¸ªæŠ€æœ¯é¡¹ç›®çš„æ‰§è¡Œè®¡åˆ’ï¼ŒåŒ…æ‹¬å…³é”®æ­¥éª¤å’Œæ³¨æ„äº‹é¡¹ã€‚"
                
                start_time = time.time()
                response = self.llm_client.call(task_prompt, persistent_context)
                end_time = time.time()
                
                response_time = end_time - start_time
                true_kv_times.append(response_time)
                
                print(f"     å“åº”æ—¶é—´: {response_time:.2f}s")
                # print(f"     å®ŒæˆåContexté•¿åº¦: {len(persistent_context.get_history())}")
                
                # åªåˆ é™¤éå‰ç¼€éƒ¨åˆ†ï¼Œä¿æŒMASåŸºç¡€æç¤ºè¯ä¸åŠ¨

                current_length = len(persistent_context.get_history())
                message_to_delete = current_length - initial_length

                # print(f"     éœ€è¦åˆ é™¤çš„æ¶ˆæ¯æ•°: {message_to_delete}")

                # é€ä¸ªåˆ é™¤åç»­æ·»åŠ çš„æ¶ˆæ¯
                for j in range(message_to_delete):
                    if len(persistent_context.get_history()) > initial_length:
                        persistent_context.remove_last_message()
                        # print(f"     å·²åˆ é™¤ç¬¬{j+1}æ¡æ¶ˆæ¯, å‰©ä½™{len(persistent_context.get_history())}")
                        
                final_length = len(persistent_context.get_history())
                # print(f"     æ¸…ç†å®Œæˆï¼Œæœ€ç»ˆContexté•¿åº¦: {final_length}")


                # ğŸ” éªŒè¯MASåŸºç¡€æç¤ºè¯å¯¹è±¡æ˜¯å¦è¢«åŠ¨è¿‡
                current_mas_id = id(persistent_context.history[0])
                current_mas_hash = hash(persistent_context.history[0]["content"])
                
                mas_object_unchanged = (current_mas_id == mas_message_id)
                mas_content_unchanged = (current_mas_hash == mas_message_content_hash)
                
                # if mas_object_unchanged and mas_content_unchanged:
                #     print(f"     ğŸ‰ MASåŸºç¡€æç¤ºè¯å¯¹è±¡å®Œå…¨æœªåŠ¨è¿‡ï¼")
                # else:
                #     print(f"     âš ï¸  MASåŸºç¡€æç¤ºè¯å¯¹è±¡è¢«æ”¹åŠ¨äº†ï¼")
                
                time.sleep(2)
            except Exception as e:
                print(f"  âŒ å¤„ç† {config_file} æ—¶å‡ºé”™: {e}")
                continue

         # åˆ†æKVCacheæ•ˆæœ
        if true_kv_times:
            avg_time = statistics.mean(true_kv_times)
            print(f"\n  ğŸ“ˆ å¹³å‡æ—¶é—´: {avg_time:.2f}s")
            print(f"  ğŸ“Š æ—¶é—´èŒƒå›´: {min(true_kv_times):.2f}s - {max(true_kv_times):.2f}s")
            
            if len(true_kv_times) >= 3:
                first_time = true_kv_times[0]
                subsequent_times = true_kv_times[1:]
                avg_subsequent = statistics.mean(subsequent_times)
                
                improvement = ((first_time - avg_subsequent) / first_time) * 100
                
                print(f"\n  ğŸ” æ•ˆæœåˆ†æ:")
                print(f"     ç¬¬1æ¬¡å“åº”æ—¶é—´: {first_time:.2f}s")
                print(f"     åç»­å¹³å‡æ—¶é—´: {avg_subsequent:.2f}s")
                print(f"     æ€§èƒ½æå‡: {improvement:+.1f}%")
                
                if improvement > 25:
                    print(f"     ğŸ‰ å¼ºçƒˆçš„KVCacheæ•ˆæœï¼ç­–ç•¥éå¸¸æœ‰æ•ˆ")
                elif improvement > 15:
                    print(f"     âœ… æ˜æ˜¾çš„KVCacheæ•ˆæœï¼Œå‰ç¼€å®Œå…¨ä¿æŒç­–ç•¥æœ‰æ•ˆ")
                elif improvement > 5:
                    print(f"     ğŸ¤” è½»å¾®çš„KVCacheæ•ˆæœ")
                else:
                    print(f"     âŒ æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„KVCacheæ•ˆæœ")
                    print(f"     ğŸ’¡ å¯èƒ½æ˜¯æœåŠ¡å™¨ä¸æ”¯æŒæˆ–ç½‘ç»œå»¶è¿Ÿå½±å“")

        self.test_results.append({
            "test_name": "absolutely_no_touch_prefix",
            "times": true_kv_times,
            "average": statistics.mean(true_kv_times) if true_kv_times else 0,
            "description": "ä¸åŠ¨MASåŸºç¡€æç¤ºè¯å¯¹è±¡æµ‹è¯•",
            "strategy": "ä½¿ç”¨remove_last_messageç²¾ç¡®æ¸…ç†ï¼ŒMASå¯¹è±¡å®Œå…¨ä¸åŠ¨"
        })
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        with open("absolutely_no_touch_kv_cache_results.json", "w", encoding="utf-8") as f:
            json.dump({
                "timestamp": time.time(),
                "test_strategy": "ç»å¯¹ä¸åŠ¨MASåŸºç¡€æç¤ºè¯å¯¹è±¡",
                "mas_object_preservation": "å®Œå…¨ä¿æŒå¯¹è±¡å¼•ç”¨ä¸å˜",
                "cleanup_method": "remove_last_messageé€ä¸ªåˆ é™¤",
                "results": self.test_results
            }, f, indent=2, ensure_ascii=False)
            


def main():
    """è¿è¡ŒMAS KVCacheæµ‹è¯•"""
    try:
        tester = MASFocusedKVCacheTest("mas/agent/configs/test_llm_config.yaml")
        tester.run_focused_test()
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    '''
    æµ‹è¯•mas_kv_cache_validationéœ€åœ¨Allenæ ¹ç›®å½•ä¸‹æ‰§è¡Œ python -m experiment.mas_kv_cache_validation
    '''
    main()